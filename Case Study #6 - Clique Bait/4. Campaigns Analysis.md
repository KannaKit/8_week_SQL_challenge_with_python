# ðŸŽ£ Case Study #6 - Clique Bait
## ðŸª„ 4. Campaigns Analysis

Generate a table that has 1 single row for every unique visit_id record and has the following columns:

* `user_id`
* `visit_id`
* `visit_start_time`: the earliest `event_time` for each visit
* `page_views`: count of page views for each visit
* `cart_adds`: count of product cart add events for each visit
* `purchase`: 1/0 flag if a purchase event exists for each visit
* `campaign_name`: map the visit to a campaign if the `visit_start_time` falls between the `start_date` and `end_date`
* `impression`: count of ad impressions for each visit
* `click`: count of ad clicks for each visit
* **(Optional column)** `cart_products`: a comma separated text value with products added to the cart sorted by the order they were added to the cart (hint: use the `sequence_number`)

Use the subsequent dataset to generate at least 5 insights for the Clique Bait team - bonus: prepare a single A4 infographic that the team can use for their management reporting sessions, be sure to emphasise the most important points from your findings.

Some ideas you might want to investigate further include:

* Identifying users who have received impressions during each campaign period and comparing each metric with other users who did not have an impression event
* Does clicking on an impression lead to higher purchase rates?
* What is the uplift in purchase rate when comparing users who click on a campaign impression versus users who do not receive an impression? What if we compare them with users who just an impression but do not click?
* What metrics can you use to quantify the success or failure of each campaign compared to eachother?

###### SQL

```TSQL
WITH cte AS(
SELECT
  user_id,
  visit_id,
  MIN(event_time) visit_start_time,
  SUM(CASE WHEN event_type=1 THEN 1 ELSE 0 END) page_views,
  SUM(CASE WHEN event_type=2 THEN 1 ELSE 0 END) cart_adds,
  STRING_AGG(event_type::TEXT, ', ') action_n,
  SUM(CASE WHEN event_type=4 THEN 1 ELSE 0 END) impression,
  SUM(CASE WHEN event_type=5 THEN 1 ELSE 0 END) click
FROM clique_bait.events e
LEFT JOIN clique_bait.users u ON e.cookie_id=u.cookie_id
GROUP BY visit_id, user_id),

cte2 AS (
SELECT
  visit_id,
  e.page_id,
  page_name,
  sequence_number
FROM clique_bait.events e
LEFT JOIN clique_bait.page_hierarchy ph ON e.page_id=ph.page_id
WHERE e.page_id NOT IN (1,2,12,13) AND event_type = 2
GROUP BY visit_id, e.page_id, page_name, sequence_number)

SELECT
  cte2.visit_id,
  (CASE WHEN cte.cart_adds != 0 THEN STRING_AGG(page_name::TEXT, ', ' ORDER BY sequence_number)
   ELSE NULL END) inside_cart
INTO inside_cart_tbl
FROM cte2
LEFT JOIN cte ON cte2.visit_id=cte.visit_id
GROUP BY cte2.visit_id, cte.cart_adds;

-------------

WITH cte AS(
SELECT
  user_id,
  visit_id,
  MIN(event_time) visit_start_time,
  SUM(CASE WHEN event_type=1 THEN 1 ELSE 0 END) page_views,
  SUM(CASE WHEN event_type=2 THEN 1 ELSE 0 END) cart_adds,
  STRING_AGG(event_type::TEXT, ', ') action_n,
  SUM(CASE WHEN event_type=4 THEN 1 ELSE 0 END) impression,
  SUM(CASE WHEN event_type=5 THEN 1 ELSE 0 END) click
FROM clique_bait.events e
LEFT JOIN clique_bait.users u ON e.cookie_id=u.cookie_id
GROUP BY visit_id, user_id)

SELECT
  user_id,
  cte.visit_id,
  visit_start_time,
  page_views,
  cart_adds,
  (CASE WHEN action_n ~ '3' THEN 1 ELSE 0 END) purchase,
  (CASE WHEN visit_start_time BETWEEN '2020-01-01' AND '2020-01-14' THEN 'BOGOF - Fishing For Compliments'
        WHEN visit_start_time BETWEEN '2020-01-15' AND '2020-01-28' THEN '25% Off - Living The Lux Life'
        WHEN visit_start_time BETWEEN '2020-02-01' AND '2020-03-31' THEN 'Half Off - Treat Your Shellf(ish)'
   ELSE NULL END) campaign_name,
  impression,
  click,
  inside_cart AS cart_products
INTO campaingns_analysis
FROM cte
LEFT JOIN inside_cart_tbl ict ON cte.visit_id=ict.visit_id;

SELECT *
FROM campaingns_analysis
LIMIT 20;
```

###### Python

```python
df=events.merge(users, how='left', on='cookie_id')

# earliest visit time

earliest = df[['visit_id', 'user_id', 'event_time']]
earliest = df.groupby(['visit_id', 'user_id'])['event_time'].min().reset_index(name='visit_start_time')

# campaign table
cam_df = earliest
cam_df['campaign'] = np.where((cam_df['visit_start_time']>='2020-01-01 00:00:00') & (cam_df['visit_start_time']<='2020-01-14 00:00:00'), 1,
                     np.where((cam_df['visit_start_time']>='2020-01-15 00:00:00') & (cam_df['visit_start_time']<='2020-01-28 00:00:00'), 2, 
                     np.where((cam_df['visit_start_time']>='2020-02-01 00:00:00') & (cam_df['visit_start_time']<='2020-03-31 00:00:00'), 3, 0)))
cam_df = cam_df.merge(c_ident, how='left', left_on='campaign', right_on='campaign_id')
cam_df = cam_df[['visit_id', 'campaign_name']]
                  
# page view count
views_df = df[df['event_type']==1].groupby('visit_id')['event_type'].count().reset_index(name='page_views')

# cart adds count
cart_df = df[df['event_type'] == 2].groupby('visit_id')['event_type'].count().reset_index(name='cart_adds')

# impression count
imp_df = df[df['event_type']==4].groupby('visit_id')['event_type'].count().reset_index(name='impression')

# click count
click_df = df[df['event_type']==5].groupby('visit_id')['event_type'].count().reset_index(name='click')


# copy df
df2=df
# change datatype for the column event_type to str to do string aggligation
df2['event_type'] = df2['event_type'].astype(str)
# sort by sequence number, string aggligation the event number
event_df = df2.sort_values(['visit_id', 'sequence_number']).groupby('visit_id', as_index=False).agg({'event_type': ', '.join})

# purchase
event_df['purchase']=np.where(event_df['event_type'].str.contains('3'), 1, 0)

# inside of cart
only_product=df
# filter out non-product pages, select only 'add to cart'
only_product=only_product[(~only_product['page_id'].isin(non_product_page)) & (only_product['event_type']=='2')].sort_values(['visit_id', 'cookie_id', 'sequence_number'])
# merge w/ page_hierarchy table
only_product=only_product.merge(p_hier, how='inner', on='page_id')
# string aggligate page_name (seafood name)
only_product=only_product.sort_values(['visit_id', 'sequence_number']).groupby('visit_id', as_index=False).agg({'page_name': ', '.join})
only_product['cart_products']=only_product['page_name']
inside_of_cart = only_product[['visit_id', 'cart_products']]

#merge all dfs
# first create a list called data_frames
data_frames = [earliest, cam_df, views_df, cart_df, imp_df, click_df, event_df, inside_of_cart]
# initialize merged_df with the first DataFrame earliest
merged_df = data_frames[0]
# repeat over the remaining df using a loop
for df in data_frames[1:]:
    merged_df = merged_df.merge(df, how='left', on='visit_id')

# select relevant columns
result=merged_df[['user_id', 'visit_id', 'visit_start_time', 'page_views', 'cart_adds', 'purchase', 'campaign_name', 'impression', 'click', 'cart_products']]

# handle null values
result['impression'] = result['impression'].fillna(0).astype(int)
result['click'] = result['click'].fillna(0).astype(int)
result['cart_adds'] = result['cart_adds'].fillna(0).astype(int)
result['campaign_name']=np.where(result['campaign_name'].isna(), 'no campaign', result['campaign_name'])

result
```

First 5 rows.

| user_id | visit_id | visit_start_time           | page_views | cart_adds | purchase | campaign_name                     | impression | click | cart_products                                                |
|---------|----------|----------------------------|------------|-----------|----------|-----------------------------------|------------|-------|--------------------------------------------------------------|
| 155	     | 001597   | 2020-02-17 00:21:45.295141 | 	10         | 6         | 1	        | Half Off - Treat Your Shellf(ish) | 	1          | 1	     | Salmon, Russian Caviar, Black Truffle, Lobster, Crab, Oyster |
| 243	     | 002809   | 2020-03-13 17:49:55.45987  | 	4          | 0         | 0	        | Half Off - Treat Your Shellf(ish) | 	0          | 0     |   null                                                           |
| 78	      | 0048b2   | 2020-02-10 02:59:51.335452 | 	6          | 4         | 0	        | Half Off - Treat Your Shellf(ish) | 	0          | 0	     | Kingfish, Russian Caviar, Abalone, Lobster                   |
| 228	     | 004aaf   | 2020-03-18 13:23:07.97394  | 	6          | 2         | 1	        | Half Off - Treat Your Shellf(ish) | 	0          | 0	     | Tuna, Lobster                                                |
| 237	     | 005fe7   | 2020-04-02 18:14:08.257711 | 	9          | 4         | 1        | null                              | 0          | 0	     | Kingfish, Black Truffle, Crab, Oyster                        |

---

ðŸ”Ž Insights
------

**1. Customers who purchased product(s) viewed about twice more pages and added to their cart twice more than customers who didn't buy.** 
###### SQL

```TSQL
SELECT 
	CASE WHEN purchase=0 THEN 'did not purchase'
	ELSE 'purchased' END purchase_status, 
	ROUND(AVG(page_views),2) avg_page_view,
	ROUND(AVG(cart_adds),2) avg_cart_adds
FROM campaingns_analysis
GROUP BY purchase_status;
```

###### Python

```python
df=result
df['purchase_stat']=np.where(df['purchase']==0, 'did not purchase', 'purchased')

df.groupby('purchase_stat')['page_views', 'cart_adds'].mean()
```

| purchase_status  | avg_page_view | avg_cart_adds |
|------------------|---------------|---------------|
| did not purchase | 	3.76          | 1.14          |
| purchased        | 	7.99          | 3.61          |

---

**2. The data suggests a correlation between customers who were exposed to the Clique Bait ad on search result pages or other websites and a slightly lower purchase rate. This observation implies potential areas for improvement in either the targeting strategy or the effectiveness of the Clique Bait ad.**  
###### SQL

```TSQL
SELECT
	impression impression_count,
	ROUND(SUM(purchase)::NUMERIC/(SELECT COUNT(*) FROM campaingns_analysis)::NUMERIC*100,2) purchase_percentage
FROM campaingns_analysis
GROUP BY impression;
```

###### Python

```python
total_n = df['visit_id'].count()

df = df.groupby('impression', as_index=False)['purchase'].sum()

df['purchase_percentage']=df.purchase/3564*100

df
```

| impression_count  | purchase_percentage | 
|------------------|---------------|
| 0 | 	29.18          |
| 1       | 	20.68          |

---

**3. The data suggests a correlation between customers who clicked the Clique Bait ad on search result pages or other websites and a slightly lower purchase rate. This observation implies potential areas for improvement in either the targeting strategy or the effectiveness of the Clique Bait ad.**  
###### SQL

```TSQL
SELECT
	click click_count,
	ROUND(SUM(purchase)::NUMERIC/(SELECT COUNT(*) FROM campaingns_analysis)::NUMERIC*100,2) purchase_percentage
FROM campaingns_analysis
GROUP BY click;
```

###### Python

```python
total_n = df['visit_id'].count()

df = df.groupby('impression', as_index=False)['purchase'].sum()

df['purchase_percentage']=df.purchase/3564*100

df
```

| click_count  | purchase_percentage | 
|------------------|---------------|
| 0 | 	32.35          |
| 1       | 	17.5          |

---

**4. Based on the data, it is evident that the "BOGOF - Fishing For Compliments" campaign was the most effective, with a notable increase of 3.21% in fish sales. On the other hand, the analysis reveals that the "Half Off - Treat Your Shellf(ish)" campaign resulted in only a marginal increase of 0.67% in sales within the shellfish category. Similarly, the "25% Off - Living The Lux Life" campaign experienced a decline of 0.69% in luxury item sales. Considering these results, I would recommend focusing on developing more compelling campaigns that have a stronger appeal to our customer base. Alternatively, it may be worth considering discontinuing campaigns that fail to generate significant contributions to overall sales.**  
###### SQL

```TSQL
--BOGOF - Fishing For Compliments
WITH base_table AS(
SELECT e.visit_id, product_category, campaign_name
FROM clique_bait.events AS e
LEFT JOIN clique_bait.page_hierarchy AS p ON e.page_id = p.page_id
LEFT JOIN campaingns_analysis AS c ON e.visit_id = c.visit_id 
WHERE e.visit_id IN (SELECT visit_id FROM campaingns_analysis WHERE purchase=1) AND
      e.page_id NOT IN (1,2,12,13) AND
	  e.event_type=2),

during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE campaign_name = 'BOGOF - Fishing For Compliments'
GROUP BY 1),

during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM during)),2) during_bogof
FROM during),

not_during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE visit_id NOT IN (SELECT visit_id FROM base_table WHERE campaign_name = 'BOGOF - Fishing For Compliments')
GROUP BY 1
),

not_during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM not_during)),2) not_during_bogof
FROM not_during)

SELECT d2.product_category, during_bogof, not_during_bogof, during_bogof-not_during_bogof comparison 
FROM during2 d2
INNER JOIN not_during2 nd2 ON d2.product_category=nd2.product_category;
```

###### Python

```python
purchased = result[result['purchase']==1]

df = events[(~events['page_id'].isin(non_product_page)) & (events['event_type']==2)].merge(purchased, how='right', on='visit_id')
df = df.merge(p_hier, how='left', on='page_id')

bogof_df = df[df['campaign_name']=='BOGOF - Fishing For Compliments']
not_bogof_df = df[df['campaign_name']!='BOGOF - Fishing For Compliments']

bogof_df = bogof_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')
not_bogof_df = not_bogof_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')

total_n = bogof_df['purchased_count'].sum()
bogof_df['during_bogof']=bogof_df['purchased_count']/total_n*100

total_num = not_bogof_df['purchased_count'].sum()
not_bogof_df['not_during_bogof']=not_bogof_df['purchased_count']/total_num*100

result_df = bogof_df.merge(not_bogof_df, how='inner', on='product_category')
result_df['comparison']=result_df.during_bogof - result_df.not_during_bogof
result_df = result_df[['product_category', 'during_bogof', 'not_during_bogof', 'comparison']]
result_df
```

| product_category | during_bogof | not_during_bogof | comparison |
|------------------|--------------|------------------|------------|
| Shellfish        | 	43.74        | 45.28            | -1.54      |
| **Fish**             | 	**35.93**        | **32.72**            | **3.21**       |
| Luxury           | 	20.33        | 22.01            | -1.68      |

---

###### SQL

```TSQL
--25% Off - Living The Lux Life
WITH base_table AS(
SELECT e.visit_id, product_category, campaign_name
FROM clique_bait.events AS e
LEFT JOIN clique_bait.page_hierarchy AS p ON e.page_id = p.page_id
LEFT JOIN campaingns_analysis AS c ON e.visit_id = c.visit_id 
WHERE e.visit_id IN (SELECT visit_id FROM campaingns_analysis WHERE purchase=1) AND
      e.page_id NOT IN (1,2,12,13) AND
	  e.event_type=2),

during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE campaign_name = '25% Off - Living The Lux Life'
GROUP BY 1),

during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM during)),2) during_bogof
FROM during),

not_during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE visit_id NOT IN (SELECT visit_id FROM base_table WHERE campaign_name = '25% Off - Living The Lux Life')
GROUP BY 1
),

not_during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM not_during)),2) not_during_bogof
FROM not_during)

SELECT d2.product_category, during_bogof, not_during_bogof, during_bogof-not_during_bogof comparison 
FROM during2 d2
INNER JOIN not_during2 nd2 ON d2.product_category=nd2.product_category;
```

###### Python

```python
df = events[(~events['page_id'].isin(non_product_page)) & (events['event_type']==2)].merge(purchased, how='right', on='visit_id')
df = df.merge(p_hier, how='left', on='page_id')

shell_df = df[df['campaign_name']=='25% Off - Living The Lux Life']
not_shell_df = df[df['campaign_name']!='25% Off - Living The Lux Life']

shell_df = shell_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')
not_shell_df = not_shell_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')

total_n = shell_df['purchased_count'].sum()
shell_df['during_shell']=shell_df['purchased_count']/total_n*100

total_num = not_shell_df['purchased_count'].sum()
not_shell_df['not_during_shell']=not_shell_df['purchased_count']/total_num*100

result_df = shell_df.merge(not_shell_df, how='inner', on='product_category')
result_df['comparison']=result_df.during_shell - result_df.not_during_shell
result_df = result_df[['product_category', 'during_shell', 'not_during_shell', 'comparison']]
result_df
```

| product_category | during_lux | not_during_lux | comparison |
|------------------|--------------|------------------|------------|
| Shellfish        | 	45.10        | 45.17            | -0.07      |
| Fish             | 	33.46        | 32.89            | 0.57       |
| **Luxury**           | 	**21.44**        | **21.94**            | **-0.5**      |

---

###### SQL

```TSQL
--Half Off - Treat Your Shellf(ish)
WITH base_table AS(
SELECT e.visit_id, product_category, campaign_name
FROM clique_bait.events AS e
LEFT JOIN clique_bait.page_hierarchy AS p ON e.page_id = p.page_id
LEFT JOIN campaingns_analysis AS c ON e.visit_id = c.visit_id 
WHERE e.visit_id IN (SELECT visit_id FROM campaingns_analysis WHERE purchase=1) AND
      e.page_id NOT IN (1,2,12,13) AND
	  e.event_type=2),

during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE campaign_name = 'Half Off - Treat Your Shellf(ish)'
GROUP BY 1),

during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM during)),2) during_bogof
FROM during),

not_during AS(
SELECT product_category, COUNT(*) purchased
FROM base_table
WHERE visit_id NOT IN (SELECT visit_id FROM base_table WHERE campaign_name = 'Half Off - Treat Your Shellf(ish)')
GROUP BY 1
),

not_during2 AS(
SELECT product_category, ROUND(100*(purchased/(SELECT SUM(purchased) FROM not_during)),2) not_during_bogof
FROM not_during)

SELECT d2.product_category, during_bogof, not_during_bogof, during_bogof-not_during_bogof comparison 
FROM during2 d2
INNER JOIN not_during2 nd2 ON d2.product_category=nd2.product_category;
```

###### Python

```python
df = events[(~events['page_id'].isin(non_product_page)) & (events['event_type']==2)].merge(purchased, how='right', on='visit_id')
df = df.merge(p_hier, how='left', on='page_id')

shell_df = df[df['campaign_name']=='Half Off - Treat Your Shellf(ish)']
not_shell_df = df[df['campaign_name']!='Half Off - Treat Your Shellf(ish)']

shell_df = shell_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')
not_shell_df = not_shell_df.groupby('product_category')['page_id'].count().reset_index(name='purchased_count')

total_n = shell_df['purchased_count'].sum()
shell_df['during_shell']=shell_df['purchased_count']/total_n*100

total_num = not_shell_df['purchased_count'].sum()
not_shell_df['not_during_shell']=not_shell_df['purchased_count']/total_num*100

result_df = shell_df.merge(not_shell_df, how='inner', on='product_category')
result_df['comparison']=result_df.during_shell - result_df.not_during_shell
result_df = result_df[['product_category', 'during_shell', 'not_during_shell', 'comparison']]
result_df
```

| product_category | during_half | not_during_half | comparison |
|------------------|--------------|------------------|------------|
| **Shellfish**       | 	**45.39**        | **44.72**            | **0.67**      |
| Fish             | 	32.27        | 34.29            | -2.02       |
| Luxury           | 	22.34        | 20.99            | 1.35      |
